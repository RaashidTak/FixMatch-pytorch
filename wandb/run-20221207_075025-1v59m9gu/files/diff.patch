diff --git a/train.py b/train.py
index 401254f..e60fda5 100644
--- a/train.py
+++ b/train.py
@@ -19,6 +19,8 @@ from tqdm import tqdm
 
 from dataset.cifar import DATASET_GETTERS
 from utils import AverageMeter, accuracy
+import wandb
+wandb.init(project="fixmatch-python-run2")
 
 logger = logging.getLogger(__name__)
 best_acc = 0
@@ -81,7 +83,7 @@ def main():
     parser.add_argument('--arch', default='wideresnet', type=str,
                         choices=['wideresnet', 'resnext'],
                         help='dataset name')
-    parser.add_argument('--total-steps', default=2**20, type=int,
+    parser.add_argument('--total-steps', default=2**10, type=int,
                         help='number of total steps to run')
     parser.add_argument('--eval-step', default=1024, type=int,
                         help='number of eval steps to run')
@@ -313,7 +315,7 @@ def train(args, labeled_trainloader, unlabeled_trainloader, test_loader,
 
     labeled_iter = iter(labeled_trainloader)
     unlabeled_iter = iter(unlabeled_trainloader)
-
+    wandb.watch(model)
     model.train()
     for epoch in range(args.start_epoch, args.epochs):
         batch_time = AverageMeter()
@@ -438,7 +440,14 @@ def train(args, labeled_trainloader, unlabeled_trainloader, test_loader,
             logger.info('Best top-1 acc: {:.2f}'.format(best_acc))
             logger.info('Mean top-1 acc: {:.2f}\n'.format(
                 np.mean(test_accs[-20:])))
-
+        wandb.log({
+            "Epoch": epoch,
+            "Test Loss": test_loss,
+            "Test Acc": test_acc,
+            "Train Loss": losses.avg,
+            "Train Loss x": losses_x.avg,
+            "Train Loss u": losses_u.avg,
+            "Mask": mask_probs.avg})
     if args.local_rank in [-1, 0]:
         args.writer.close()
 
